# LLM Orchestrator

> Legacy reference only. Superseded by `02-system-architecture.md`, `03-canonical-contracts.md`, and `07-implementation-roadmap.md`.

Perfect. Now we plug in the LLM Orchestrator properly â€” with:

- Prompt builder
- Tool schema
- Tool parsing
- Fake model adapter (runs without API key)
- Real OpenAI adapter (drop-in)
- RPC call to realtime server

You'll be able to switch between fake DM and real LLM instantly.

---

## 1ï¸âƒ£ apps/llm-orchestrator Setup

### package.json

```json
{
  "name": "@rpg-ai/llm-orchestrator",
  "private": true,
  "type": "module",
  "scripts": {
    "dev": "tsx watch src/main.ts",
    "start": "node dist/main.js",
    "build": "tsc -p tsconfig.json"
  },
  "dependencies": {
    "zod": "^3.24.1",
    "node-fetch": "^3.3.2"
  },
  "devDependencies": {
    "tsx": "^4.19.2",
    "typescript": "^5.7.3",
    "@types/node": "^20.17.12"
  }
}
```

### tsconfig.json

```json
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "ES2022",
    "moduleResolution": "Bundler",
    "outDir": "dist",
    "rootDir": "src",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true
  },
  "include": ["src"]
}
```

---

## 2ï¸âƒ£ Prompt Builder

### src/prompts/dmPrompt.ts

```ts
export function buildDmPrompt(input: {
  snapshot: any;
  recentEvents: any[];
  playerText: string;
  edition: string;
}) {
  return `
You are a Dungeon Master running a ${input.edition} game.

STRICT RULES:
- Never invent dice results.
- Use tool calls for rolls and state changes.
- Keep narration immersive but concise.
- Always end with 3-6 options for players.

CURRENT SNAPSHOT:
${JSON.stringify(input.snapshot, null, 2)}

RECENT EVENTS:
${JSON.stringify(input.recentEvents.slice(-10), null, 2)}

PLAYER ACTION:
"${input.playerText}"

Respond in JSON:

{
  "narration": "...",
  "tool_calls": [],
  "options": ["..."]
}
`;
}
```

---

## 3ï¸âƒ£ Tool Schema

### src/tools/toolSchema.ts

```ts
export const toolDefinitions = [
  {
    name: "roll",
    description: "Request a dice roll",
    parameters: {
      type: "object",
      properties: {
        formula: { type: "string" },
        reason: { type: "string" },
      },
      required: ["formula", "reason"],
    },
  },
  {
    name: "apply_state_patch",
    description: "Request a state change",
    parameters: {
      type: "object",
      properties: {
        reason: { type: "string" },
        patches: { type: "array" },
      },
      required: ["reason", "patches"],
    },
  },
];
```

---

## 4ï¸âƒ£ Fake Model Adapter (no API key needed)

This makes development easy.

### src/model/fakeModel.ts

```ts
export async function runFakeModel(prompt: string) {
  const playerLine = prompt.match(/PLAYER ACTION:\n"(.*?)"/s)?.[1] ?? "";

  return {
    narration: `You attempt: "${playerLine}". The world shifts subtly.`,
    tool_calls: [],
    options: [
      "Look around carefully",
      "Move forward cautiously",
      "Call out to anyone nearby",
      "Do something unexpected",
    ],
  };
}
```

---

## 5ï¸âƒ£ Real OpenAI Adapter (optional)

Drop your API key later.

### src/model/openaiModel.ts

```ts
import fetch from "node-fetch";

export async function runOpenAIModel(prompt: string) {
  const response = await fetch("https://api.openai.com/v1/responses", {
    method: "POST",
    headers: {
      Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      model: "gpt-5-mini",
      input: prompt,
    }),
  });

  const data = await response.json();

  const text = data.output_text ?? "{}";
  return JSON.parse(text);
}
```

---

## 6ï¸âƒ£ Orchestrator Core

### src/orchestrate.ts

```ts
import { buildDmPrompt } from "./prompts/dmPrompt.js";
import { runFakeModel } from "./model/fakeModel.js";
// import { runOpenAIModel } from "./model/openaiModel.js";

export async function orchestrateTurn(params: {
  snapshot: any;
  recentEvents: any[];
  playerText: string;
  edition: string;
}) {
  const prompt = buildDmPrompt(params);

  // Switch here later
  const result = await runFakeModel(prompt);
  // const result = await runOpenAIModel(prompt);

  return result;
}
```

---

## 7ï¸âƒ£ RPC Endpoint to Realtime

### src/main.ts

```ts
import Fastify from "fastify";
import fetch from "node-fetch";
import { orchestrateTurn } from "./orchestrate.js";

const app = Fastify({ logger: true });

app.post("/orchestrate", async (req, res) => {
  const body = req.body as any;

  const result = await orchestrateTurn({
    snapshot: body.snapshot,
    recentEvents: body.recentEvents,
    playerText: body.playerText,
    edition: body.edition ?? "5e",
  });

  return result;
});

app.listen({ port: 8083, host: "0.0.0.0" });
```

**Run:**

```bash
cd apps/llm-orchestrator
pnpm i
pnpm dev
```

---

## 8ï¸âƒ£ Connect Realtime â†’ Orchestrator

Replace DM stub in realtime server. Inside `client.player_action` block:

```ts
const response = await fetch("http://localhost:8083/orchestrate", {
  method: "POST",
  headers: { "Content-Type": "application/json" },
  body: JSON.stringify({
    snapshot: (await readSnapshot(msg.campaign_id)).state,
    recentEvents: [],
    playerText: msg.text,
    edition: "5e",
  }),
});

const dmResult = await response.json();

const dmEvent = await appendEvent(
  msg.campaign_id,
  "dm_narration",
  {
    text: dmResult.narration,
    options: dmResult.options ?? [],
  },
  (state) => state,
);

broadcastEvent(msg.campaign_id, dmEvent);
```

---

## ðŸŽ‰ What You Now Have

You now have:

- Event-sourced multiplayer server
- Snapshot-based state
- WS real-time sync
- LLM orchestrator service
- Switchable fake/real model
- Structured DM output
- Extensible tool system

---

## ðŸš€ Next Real Upgrade

The next serious step is:

- Implement real roll tool with server-generated dice
- Add apply_state_patch validation
- Add RAG retrieval injection
- Add summarization compression
- Add persistent NPC memory graph

This is already architected correctly.

---

If you want to level this into "serious startup-grade system", next you can:

- Convert this into a production-ready microservice architecture
- Add Redis pub/sub scaling for multi-instance realtime
- Add JWT auth
- Add rate limiting + cost tracking per campaign
- Add voice pipeline (text â†’ TTS â†’ streamed audio)

---

# âœ… Production-grade upgrade (v1.5 â†’ startup-grade)

This section upgrades the previous "LLM Orchestrator" setup into a production-ready architecture:

- JWT auth (REST + WS)
- Redis Pub/Sub scaling for multi-instance realtime
- Rate limiting + abuse protection
- Cost tracking per campaign/user
- Voice pipeline (DM TTS, later NPC voices)

---

## A) Auth: JWT everywhere (API issues tokens, Realtime verifies)

1. **API login returns:** access_token (JWT, 15m), refresh_token (JWT or opaque, 30d).

2. **JWT claims (minimum):** sub (user_id), cid (optional current campaign_id), role (player|gm, optional).

3. **Realtime WS connection:** `wss://.../ws?token=<access_token>`

4. **Realtime verifies token signature locally** (NO DB roundtrip on every message).

**Suggested libs:** API and Realtime: `jose`

**JWT verification sketch (Realtime):**

```ts
import { jwtVerify } from "jose";

const JWT_SECRET = new TextEncoder().encode(process.env.JWT_SECRET!);

async function verifyWsToken(token: string) {
  const { payload } = await jwtVerify(token, JWT_SECRET);
  return {
    userId: String(payload.sub),
    role: payload.role ? String(payload.role) : "player",
  };
}
```

---

## B) Redis Pub/Sub scaling (multiple realtime instances)

**Problem:** With multiple WS servers, broadcasts must reach clients connected to other instances.

**Solution:** Each realtime instance:

- Subscribes to Redis channel `campaign:<id>`
- Publishes newly appended events to the same channel
- Local roomHub broadcasts to local connections

**Recommended:** ioredis

**Publish after appendEvent:**

```ts
await redis.publish(`campaign:${campaignId}`, JSON.stringify(event));
```

**Subscribe on startup:**

```ts
redisSub.psubscribe("campaign:*");
redisSub.on("pmessage", (_pattern, channel, msg) => {
  const event = JSON.parse(msg);
  const campaignId = channel.split(":")[1];
  broadcastEvent(campaignId, event);
});
```

**Important:** Still keep Postgres as the authoritative store. Redis is just transport.

---

## C) Rate limiting + abuse protection

**Where to limit:**

1. REST API: login/register, uploads, rag_search
2. Realtime: player_action frequency
3. Orchestrator: model calls per user/campaign

**API (Fastify):** @fastify/rate-limit

**Realtime:** In-memory token bucket per connection AND per campaign. Also enforce max message size and per-minute actions.

**Example (Realtime simple limiter):**

```ts
const buckets = new Map<string, { tokens: number; last: number }>();

function allow(key: string, refillPerSec = 0.5, burst = 10) {
  const now = Date.now();
  const b = buckets.get(key) ?? { tokens: burst, last: now };
  const delta = (now - b.last) / 1000;
  b.tokens = Math.min(burst, b.tokens + delta * refillPerSec);
  b.last = now;
  if (b.tokens < 1) {
    buckets.set(key, b);
    return false;
  }
  b.tokens -= 1;
  buckets.set(key, b);
  return true;
}
```

Use key = `user:${userId}` and/or `campaign:${campaignId}`.

---

## D) Cost tracking (per campaign + per user)

**Add tables:** model_usage (append-only), campaign_budget (optional)

```sql
create table if not exists model_usage (
  id uuid primary key default uuid_generate_v4(),
  campaign_id uuid not null,
  user_id uuid,
  provider text not null,          -- openai, etc
  model text not null,             -- gpt-5-mini
  purpose text not null,           -- dm_turn, summary, rag_rewrite
  input_tokens int not null default 0,
  output_tokens int not null default 0,
  cost_usd numeric(10,4) not null default 0,
  created_at timestamptz not null default now()
);

create index if not exists idx_model_usage_campaign_time on model_usage(campaign_id, created_at);
create index if not exists idx_model_usage_user_time on model_usage(user_id, created_at);

create table if not exists campaign_budget (
  campaign_id uuid primary key,
  daily_cap_usd numeric(10,4) not null default 1.0000,
  hard_stop boolean not null default false,
  updated_at timestamptz not null default now()
);
```

**Orchestrator responsibility:** After every model call, insert one row into model_usage. Enforce budget by checking last 24h spend before calling model.

**Budget check query:**

```sql
select coalesce(sum(cost_usd), 0) as spend
from model_usage
where campaign_id = $1 and created_at > now() - interval '24 hours';
```

---

## E) Orchestrator: structured JSON output + strict parsing

Upgrade from "prompt returns JSON" to:

- Enforce schema using zod.
- If parse fails: retry once with a repair prompt; otherwise fall back to safe DM response.

**Zod schema:**

```ts
import { z } from "zod";

export const DmResponse = z.object({
  narration: z.string().min(1),
  tool_calls: z
    .array(
      z.object({
        name: z.string(),
        args: z.record(z.any()),
      }),
    )
    .default([]),
  options: z.array(z.string()).min(1).max(8).default([]),
});
```

---

## F) Tool execution: move ALL tools to Realtime (authoritative)

**Rule:**

- Orchestrator never mutates DB.
- Orchestrator only proposes tool calls.
- Realtime validates + appends events + updates snapshot.

**Realtime internal endpoint:** POST /internal/tools/execute â€” protected by internal shared secret or mTLS

**Orchestrator call:** Send tool_calls + dm_narration payload

**Realtime executes:**

1. roll â†’ append roll_requested + roll_result
2. apply_state_patch â†’ validate â†’ append state_patch_requested + state_patch_applied
3. create_entity â†’ append entity_created
4. trigger_audio â†’ append audio_cue
5. dm_narration last

---

## G) Voice pipeline (v2-ready, can start in v1.5)

**Goal:** DM narration becomes both text and audio.

**Approach:**

1. Orchestrator returns narration text.
2. Worker converts narration â†’ TTS audio.
3. Realtime emits an event pointing to audio URL.
4. Client plays audio (and still shows text).

**Add event:** dm_audio_ready

**Payload:** url, voice_id (dm_default), duration_ms

**Suggested flow:** dm_narration appended immediately â†’ enqueue TTS job â†’ when done: append dm_audio_ready

**Client:** if audio_autoplay enabled, play

**NPC voices later:** npc.voice_profile stored in DB, voice selection per line

---

## H) Observability (don't skip this)

**Minimum:**

- request_id correlation across API â†’ realtime â†’ orchestrator â†’ worker
- structured logs (JSON)
- metrics: ws connections, events/sec, model calls/sec, avg tokens/turn, spend/day

**Tools:** pino logs, OpenTelemetry (later)

---

## I) Deployment notes (simple path)

| Phase       | Approach                                                                              |
| ----------- | ------------------------------------------------------------------------------------- |
| **Phase 1** | Single VPS, Docker Compose, Nginx reverse proxy, Postgres + Redis managed if possible |
| **Phase 2** | Separate realtime instances behind LB (sticky sessions), Redis pub/sub enabled        |
| **Phase 3** | K8s + autoscaling                                                                     |

---

## Action items checklist (what to implement next)

1. Add JWT issuance in API + verification in Realtime
2. Add Redis pub/sub to Realtime roomHub broadcasts
3. Add per-user/per-campaign rate limiting
4. Add model_usage table + orchestrator inserts + budget enforcement
5. Add /internal/tools/execute on Realtime (authoritative tools)
6. Add TTS worker job + dm_audio_ready event

---

**Done** â€” Full "startup-grade upgrade" with concrete implementation notes for:

- JWT auth (API issues, Realtime verifies)
- Redis Pub/Sub scaling (multi-instance WS)
- Rate limiting (REST + WS + orchestrator)
- Cost tracking tables + budget enforcement
- Authoritative tool execution via Realtime /internal/tools/execute
- Voice pipeline (dm_audio_ready event + worker TTS job)
- Observability + deployment phases
